# streamlit_app.py
"""
Streamlit ëŒ€ì‹œë³´ë“œ (í•œêµ­ì–´ UI)
- ê³µê°œ ë°ì´í„° ëŒ€ì‹œë³´ë“œ: NASA GISS GISTEMP ì›”ë³„ ì „ì§€êµ¬ ì˜¨ë„ ì´ìƒì¹˜(Anomaly) CSV ì‚¬ìš©
    ì¶œì²˜: https://data.giss.nasa.gov/gistemp/ 
    ì§ì ‘ CSV íŒŒì¼: https://data.giss.nasa.gov/gistemp/tabledata_v4/GLB.Ts+dSST.csv
- ì‚¬ìš©ì ì…ë ¥ ëŒ€ì‹œë³´ë“œ: ì´ í”„ë¡¬í”„íŠ¸ì˜ 'Input' ì„¹ì…˜ì— ë°ì´í„°ê°€ ì—†ì„ ê²½ìš° ì˜ˆì‹œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë™ì‘ ì‹œì—°
- êµ¬í˜„ ê·œì¹™:
    - date, value, group(optional) í‘œì¤€í™”
    - ê²°ì¸¡/í˜•ë³€í™˜/ì¤‘ë³µ ì²˜ë¦¬
    - ë¯¸ë˜ ë‚ ì§œ ì œê±° (ë¡œì»¬ ì‹œìŠ¤í…œì˜ í˜„ì¬ ë‚ ì§œ ê¸°ì¤€)
    - @st.cache_data ì‚¬ìš©
    - ì „ì²˜ë¦¬ëœ í‘œ CSV ë‹¤ìš´ë¡œë“œ ì œê³µ
- ë¹„ê³ : kaggle API ì‚¬ìš© ì‹œ ë³„ë„ ì¸ì¦ ì•ˆë‚´ë¥¼ ì£¼ì„ìœ¼ë¡œ ì¶”ê°€ (ë³¸ ì½”ë“œì—ì„œëŠ” kaggle ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
"""

from io import StringIO
import requests
import pandas as pd
import numpy as np
import datetime
import time
import plotly.express as px
import plotly.graph_objects as go
import streamlit as st
from dateutil import parser as dateparse
from requests.adapters import HTTPAdapter, Retry

# -------------------------
# ê¸°ë³¸ ì„¤ì • (í•œêµ­ì–´ UI)
# -------------------------
st.set_page_config(page_title="ë°ì´í„° ëŒ€ì‹œë³´ë“œ (Streamlit + Codespaces)", layout="wide")

# Pretendard í°íŠ¸ ì ìš© ì‹œë„ (ìˆìœ¼ë©´ ì ìš©, ì—†ìœ¼ë©´ ë¬´ì‹œ)
st.markdown(
    """
    <style>
    @font-face {
        font-family: 'Pretendard';
        src: url('/fonts/Pretendard-Bold.ttf') format('truetype');
        font-weight: 700;
        font-style: normal;
    }
    html, body, [class*="css"]  {
        font-family: 'Pretendard', system-ui, -apple-system, "Segoe UI", Roboto, "Helvetica Neue", Arial;
    }
    </style>
    """,
    unsafe_allow_html=True,
)

st.title("ğŸ“Š ë°ì´í„° ëŒ€ì‹œë³´ë“œ â€” ê³µê°œ ë°ì´í„° + ì‚¬ìš©ì ì…ë ¥ ë°ì´í„° (í•œêµ­ì–´ UI)")
st.caption("ê³µê°œ ë°ì´í„°: NASA GISS GISTEMP (ì „ì§€êµ¬ ì›”ë³„ ì˜¨ë„ ì´ìƒì¹˜). ì‚¬ìš©ì ì…ë ¥ ë°ì´í„°: í”„ë¡¬í”„íŠ¸ Input ì„¹ì…˜ ê¸°ë°˜ (ì—†ìœ¼ë©´ ì˜ˆì‹œ ì‚¬ìš©).")

# ìœ í‹¸: í˜„ì¬ ë¡œì»¬ ë‚ ì§œ(ì•±ì´ ì‹¤í–‰ë˜ëŠ” ë¨¸ì‹  ì‹œê°„)
TODAY = datetime.datetime.now().date()

# -------------------------
# í—¬í¼ í•¨ìˆ˜: ì•ˆì „í•œ HTTP ê°€ì ¸ì˜¤ê¸° (ì¬ì‹œë„ + ëŒ€ì²´ ë°ì´í„°)
# -------------------------
def requests_get_with_retry(url, max_retries=3, backoff=1.0, timeout=15):
    session = requests.Session()
    retries = Retry(total=max_retries, backoff_factor=backoff, status_forcelist=[429,500,502,503,504])
    session.mount("https://", HTTPAdapter(max_retries=retries))
    session.mount("http://", HTTPAdapter(max_retries=retries))
    resp = session.get(url, timeout=timeout)
    resp.raise_for_status()
    return resp

@st.cache_data(show_spinner=False)
def fetch_gistemp_csv(url="https://data.giss.nasa.gov/gistemp/tabledata_v4/GLB.Ts+dSST.csv"):
    """
    NASA GISTEMP CSVë¥¼ ì‹œë„í•´ ê°€ì ¸ì˜¨ë‹¤.
    ì‹¤íŒ¨ ì‹œ None ë°˜í™˜ (í˜¸ì¶œë¶€ì—ì„œ ì˜ˆì‹œ ë°ì´í„°ë¡œ ìë™ ëŒ€ì²´)
    ì¶œì²˜ ì£¼ì„: https://data.giss.nasa.gov/gistemp/ , CSV: https://data.giss.nasa.gov/gistemp/tabledata_v4/GLB.Ts+dSST.csv
    """
    try:
        resp = requests_get_with_retry(url)
        resp.encoding = 'utf-8'
        text = resp.text
        return text
    except Exception as e:
        # ì¬ì‹œë„ ì´ë¯¸ ìˆ˜í–‰. ì—¬ê¸°ì„œ ì‹¤íŒ¨í•˜ë©´ None ë°˜í™˜
        return None

# -------------------------
# ê³µê°œ ë°ì´í„° ëŒ€ì‹œë³´ë“œ: NASA GISTEMP ê°€ì ¸ì˜¤ê¸° -> ì „ì²˜ë¦¬
# -------------------------
st.header("1. ê³µê°œ ë°ì´í„° ëŒ€ì‹œë³´ë“œ â€” NASA GISS (GISTEMP)")

with st.expander("ë°ì´í„° ì›ë³¸ / ì²˜ë¦¬ì„¤ëª… (í´ë¦­í•´ì„œ ë³´ê¸°)", expanded=False):
    st.markdown("""
    - ë°ì´í„° ì¶œì²˜: NASA GISS GISTEMP (ì›”ë³„ ì „ì§€êµ¬ í‰ê·  ì˜¨ë„ ì´ìƒì¹˜)
      - ë©”ì¸ í˜ì´ì§€: https://data.giss.nasa.gov/gistemp/
      - CSV íŒŒì¼(ê³µì‹): https://data.giss.nasa.gov/gistemp/tabledata_v4/GLB.Ts+dSST.csv
    - ë³¸ ì•±ì€ CSV ì§ì ‘ ê°€ì ¸ì™€ ì „ì²˜ë¦¬ (ê²°ì¸¡/ì¤‘ë³µ/í˜•ë³€í™˜/ë¯¸ë˜ ë‚ ì§œ ì œê±°) í›„ ì‹œê°í™”í•©ë‹ˆë‹¤.
    - ë§Œì•½ ì›ê²© CSV í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ìë™ìœ¼ë¡œ ì˜ˆì‹œ(ëŒ€ì²´) ë°ì´í„°ë¡œ ì „í™˜í•˜ë©°, í™”ë©´ì— ì•ˆë‚´ ë©”ì‹œì§€ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.
    - (ì°¸ê³ ) kaggle API ì‚¬ìš©ë²•ì´ í•„ìš”í•œ ê²½ìš° ë³„ë„ ì•ˆë‚´ í•„ìš”í•©ë‹ˆë‹¤. ì´ ìƒ˜í”Œì€ kaggleì„ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    """)

raw_text = fetch_gistemp_csv()
using_example_public = False

if raw_text is None:
    using_example_public = True
    st.warning("ê³µê°œ ë°ì´í„°(GISTEMP) ë‹¤ìš´ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì˜ˆì‹œ ë°ì´í„°ë¡œ ëŒ€ì²´í•˜ì—¬ í‘œì‹œí•©ë‹ˆë‹¤. (ì›ì¸: ë„¤íŠ¸ì›Œí¬ ë˜ëŠ” ì›ê²© ì„œë²„ ì°¨ë‹¨)")
    # ê°„ë‹¨ ì˜ˆì‹œ ë°ì´í„° (ì—°-ì›”, anomaly)
    example_public_csv = """Year,Jan,Feb,Mar,Apr,May,Jun,Jul,Aug,Sep,Oct,Nov,Dec,Annual
    2020,0.92,0.79,0.98,0.91,0.85,0.84,0.90,0.86,0.76,0.84,0.89,0.95,0.86
    2021,0.98,0.76,0.85,1.02,0.92,0.88,0.95,0.90,0.80,0.88,0.94,0.99,0.90
    2022,1.05,0.92,1.10,1.12,1.03,0.98,1.00,0.99,0.88,0.96,1.02,1.08,1.03
    2023,1.12,1.00,1.15,1.20,1.10,1.05,1.08,1.02,0.95,1.03,1.09,1.14,1.08
    """
    raw_text = example_public_csv

# íŒŒì‹±: NASA CSV íŒŒì¼ì€ ë…„ë„ í–‰ + 12ê°œì›” ì—´ + ì—°í‰ê·  ì—´ êµ¬ì¡°
def parse_gistemp_table(text):
    """
    GISTEMPì˜ tabledata_v4 CSV/í…ìŠ¤íŠ¸ í¬ë§·ì„ íŒŒì‹±í•˜ì—¬
    date,value (ì›”ë³„) í‘œì¤€í˜•ìœ¼ë¡œ ë°˜í™˜.
    """
    # ì¼ë¶€ GISTEMP íŒŒì¼ì€ í—¤ë” ë˜ëŠ” ì£¼ì„ ë¼ì¸ìœ¼ë¡œ ì‹œì‘. Pandasë¡œ ì½ì–´ë³´ê³ , í•´ë¥¼ ë…„ë„ ì»¬ëŸ¼ìœ¼ë¡œ ì‚¬ìš©.
    try:
        df = pd.read_csv(StringIO(text), skiprows=0)
    except Exception:
        # fallback: try different encoding/sep
        df = pd.read_csv(StringIO(text))
    # Expect columns like 'Year','Jan','Feb',...,'Dec', 'Annual'
    cols = df.columns.tolist()
    # normalize column names
    df.columns = [c.strip() for c in cols]
    month_cols = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']
    available_months = [m for m in month_cols if m in df.columns]
    records = []
    for _, row in df.iterrows():
        year = int(row['Year'])
        for i, mon in enumerate(available_months, start=1):
            raw_val = row.get(mon, np.nan)
            try:
                val = float(raw_val)
            except Exception:
                val = np.nan
            # create date
            try:
                date = datetime.date(year, i, 1)
            except Exception:
                continue
            records.append({'date': pd.to_datetime(date), 'value': val})
    df_long = pd.DataFrame.from_records(records)
    # ì •ë ¬, ì¤‘ë³µ ì œê±°
    df_long = df_long.drop_duplicates(subset=['date']).sort_values('date').reset_index(drop=True)
    return df_long

public_df = parse_gistemp_table(raw_text)

# ì „ì²˜ë¦¬: ê²°ì¸¡ ì²˜ë¦¬(ë³´ê°„), í˜•ë³€í™˜, ë¯¸ë˜ ë‚ ì§œ ì œê±°
def preprocess_timeseries(df):
    df = df.copy()
    # ensure date column is datetime
    df['date'] = pd.to_datetime(df['date'])
    # remove future dates (strictly greater than TODAY)
    df = df[df['date'].dt.date <= TODAY]
    # sort
    df = df.sort_values('date').reset_index(drop=True)
    # duplicate removal
    df = df.drop_duplicates(subset=['date'])
    # ensure numeric
    df['value'] = pd.to_numeric(df['value'], errors='coerce')
    # simple interpolation for missing values (linear)
    if df['value'].isna().any():
        df['value'] = df['value'].interpolate(method='time', limit_direction='both')
    return df

public_df = preprocess_timeseries(public_df)

# ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ì œê³µì„ ìœ„í•œ CSV
public_csv_bytes = public_df.to_csv(index=False).encode('utf-8')

# ê³µê°œ ë°ì´í„° ì‹œê°í™” UI (ì‚¬ì´ë“œë°” ì»¨íŠ¸ë¡¤)
st.subheader("ê³µê°œ ë°ì´í„°: ì „ì§€êµ¬ ì›”ë³„ ì˜¨ë„ ì´ìƒì¹˜ (GISTEMP)")
with st.sidebar.expander("ê³µê°œ ë°ì´í„° ì„¤ì • (GISTEMP)", expanded=True):
    st.write("ë°ì´í„° ì†ŒìŠ¤: NASA GISS GISTEMP (ì›”ë³„)")
    show_smoothing = st.checkbox("ì´ë™í‰ê·  ì ìš© (3ê°œì›”)", value=True)
    avg_window = st.number_input("ì´ë™í‰ê·  ê¸°ê°„ (ê°œì›”)", min_value=1, max_value=24, value=3, step=1)
    chart_kind = st.radio("ì°¨íŠ¸ ì¢…ë¥˜", options=["êº¾ì€ì„ ê·¸ë˜í”„", "ë©´ì ê·¸ë˜í”„", "ë°” ì°¨íŠ¸"], index=0)
    include_annual = st.checkbox("ì—°í‰ê· (ì—°ë„ë³„) ë¼ì¸ í‘œì‹œ", value=False)

# ê¸°ë³¸ ì°¨íŠ¸ (Plotly)
if public_df.empty:
    st.error("ê³µê°œ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
else:
    df_plot = public_df.copy()
    if show_smoothing and avg_window > 1:
        df_plot['smoothed'] = df_plot['value'].rolling(window=avg_window, min_periods=1, center=True).mean()
        y_col = 'smoothed'
    else:
        y_col = 'value'

    fig = go.Figure()
    if chart_kind == "êº¾ì€ì„ ê·¸ë˜í”„":
        fig.add_trace(go.Scatter(x=df_plot['date'], y=df_plot[y_col], mode='lines+markers', name='ì›”ë³„ ì´ìƒì¹˜'))
    elif chart_kind == "ë©´ì ê·¸ë˜í”„":
        fig.add_trace(go.Scatter(x=df_plot['date'], y=df_plot[y_col], mode='lines', fill='tozeroy', name='ì›”ë³„ ì´ìƒì¹˜(ë©´ì )'))
    else:
        fig = px.bar(df_plot, x='date', y=y_col, labels={'date':'ë‚ ì§œ','value':'ì´ìƒì¹˜ (Â°C)'})
    # ì—°í‰ê·  ë¼ì¸ ê³„ì‚° ë° í‘œì‹œ (ì˜µì…˜)
    if include_annual:
        df_plot['year'] = df_plot['date'].dt.year
        annual = df_plot.groupby('year')[y_col].mean().reset_index()
        # convert year to date at mid-year for plotting
        annual['date'] = pd.to_datetime(annual['year'].astype(str) + '-07-01')
        fig.add_trace(go.Scatter(x=annual['date'], y=annual[y_col], mode='lines+markers', name='ì—°í‰ê· ', line=dict(dash='dash', width=2)))
    fig.update_layout(title="ì „ì§€êµ¬ ì›”ë³„ ì˜¨ë„ ì´ìƒì¹˜ (NASA GISTEMP)",
                      xaxis_title="ë‚ ì§œ",
                      yaxis_title="ì´ìƒì¹˜ (Â°C)",
                      hovermode='x unified',
                      legend_title_text='í•­ëª©')
    st.plotly_chart(fig, use_container_width=True)

# ê³µê°œ ë°ì´í„° í…Œì´ë¸” + CSV ë‹¤ìš´ë¡œë“œ
with st.expander("ì „ì²˜ë¦¬ëœ ê³µê°œ ë°ì´í„° í‘œ / CSV ë‹¤ìš´ë¡œë“œ", expanded=False):
    st.dataframe(public_df.tail(50))
    st.download_button(label="ì „ì²˜ë¦¬ëœ ê³µê°œ ë°ì´í„° CSV ë‹¤ìš´ë¡œë“œ", data=public_csv_bytes, file_name="gistemp_preprocessed.csv", mime="text/csv")

# -------------------------
# ì‚¬ìš©ì ì…ë ¥ ëŒ€ì‹œë³´ë“œ
# -------------------------
st.header("2. ì‚¬ìš©ì ì…ë ¥ ëŒ€ì‹œë³´ë“œ (í”„ë¡¬í”„íŠ¸ Input ì„¹ì…˜ ê¸°ë°˜)")

# ì´ í”„ë¡¬í”„íŠ¸ì˜ Input ì„¹ì…˜ì´ ë¹„ì–´ìˆëŠ” ê²ƒìœ¼ë¡œ ê°€ì •. ì•±ì€ ì‹¤í–‰ ì¤‘ íŒŒì¼ ì—…ë¡œë“œë‚˜ í…ìŠ¤íŠ¸ ì…ë ¥ì„ ìš”êµ¬í•˜ì§€ ì•ŠìŒ.
# ë”°ë¼ì„œ 'Input'ì´ ì œê³µë˜ì§€ ì•Šì•˜ì„ ë•Œ ì‚¬ìš©í•  ì˜ˆì‹œ ì‚¬ìš©ì ë°ì´í„°ë¥¼ ë‚´ë¶€ í¬í•¨.
# (ë§Œì•½ ì‚¬ìš©ìê°€ ì´í›„ Inputì„ ì œê³µí•˜ë©´ ë³¸ ì½”ë“œë¥¼ ìˆ˜ì •í•˜ì—¬ í•´ë‹¹ CSV í…ìŠ¤íŠ¸ë¥¼ ì—¬ê¸°ì— ì§ì ‘ ë¶™ì—¬ë„£ë„ë¡ í•¨)

# ì˜ˆì‹œ ì‚¬ìš©ì ë°ì´í„° (date, value, group)
# - ì‚¬ìš©ìëŠ” ë³¸ ì˜ˆì‹œ ëŒ€ì‹  ìì‹ ì˜ CSV/ì´ë¯¸ì§€/ì„¤ëª…ì„ Input ì„¹ì…˜ì— ì œê³µí•  ìˆ˜ ìˆìŒ.
example_user_csv = """date,value,group
2023-01-01,120,A
2023-02-01,130,A
2023-03-01,125,A
2023-01-01,50,B
2023-02-01,55,B
2023-03-01,60,B
2023-04-01,70,B
2024-05-01,80,A
2025-10-01,999,A
"""

# NOTE: ìœ„ ë°ì´í„°ì—ëŠ” ë¯¸ë˜(ì˜ˆ: 2025-10-01) ìƒ˜í”Œì´ ìˆì–´ ì „ì²˜ë¦¬ì—ì„œ ì œê±°ë¨(ë¡œì»¬ í˜„ì¬ì¼ ê¸°ì¤€)
user_df = pd.read_csv(StringIO(example_user_csv))
# ì „ì²˜ë¦¬ ì‚¬ìš©ì ë°ì´í„° (í‘œì¤€í™”)
def preprocess_user_df(df):
    df = df.copy()
    # í‘œì¤€ ì»¬ëŸ¼ í™•ì¸/ëŒ€ì‘
    if 'date' not in df.columns:
        # ì‹œë„: ì²« ì»¬ëŸ¼ì„ dateë¡œ ê°€ì •
        df = df.rename(columns={df.columns[0]:'date'})
    if 'value' not in df.columns:
        # ì‹œë„: ë‘ë²ˆì§¸ ì»¬ëŸ¼ì„ valueë¡œ ê°€ì •
        if len(df.columns) >= 2:
            df = df.rename(columns={df.columns[1]:'value'})
    # parse date
    df['date'] = pd.to_datetime(df['date'], errors='coerce')
    df = df.dropna(subset=['date'])
    # remove future dates
    df = df[df['date'].dt.date <= TODAY]
    # numeric value
    df['value'] = pd.to_numeric(df['value'], errors='coerce')
    # fill group if missing
    if 'group' not in df.columns:
        df['group'] = 'ê¸°ë³¸'
    df = df.drop_duplicates(subset=['date','group'])
    # missing interpolation per group (time-based)
    df = df.sort_values(['group','date']).reset_index(drop=True)
    df['value'] = df.groupby('group')['value'].apply(lambda s: s.interpolate(method='time', limit_direction='both'))
    return df

user_df = preprocess_user_df(user_df)

# ì‚¬ì´ë“œë°”: ì‚¬ìš©ì ë°ì´í„° ê´€ë ¨ ìë™ êµ¬ì„±
with st.sidebar.expander("ì‚¬ìš©ì ë°ì´í„° ì„¤ì •", expanded=False):
    st.write("ì‚¬ìš©ì ì…ë ¥ ë°ì´í„°ëŠ” ì´ í”„ë¡¬í”„íŠ¸ì˜ Input ì„¹ì…˜ì—ì„œ ì œê³µí•œ CSV/ì´ë¯¸ì§€/ì„¤ëª…ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    smoothing_user = st.checkbox("ì‚¬ìš©ì ë°ì´í„° ì´ë™í‰ê· (ê¸°ê°„ ì„ íƒ)", value=True)
    user_window = st.slider("ì´ë™í‰ê·  ê¸°ê°„(ê°œì›”)", 1, 12, 3)

if user_df.empty:
    st.warning("ì‚¬ìš©ì ì…ë ¥ ë°ì´í„°ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. (Input ì„¹ì…˜ì— ë°ì´í„°ë¥¼ ì¶”ê°€í•˜ë©´ í•´ë‹¹ ë°ì´í„°ë¡œ ëŒ€ì‹œë³´ë“œê°€ êµ¬ì„±ë©ë‹ˆë‹¤.)")
    st.info("í˜„ì¬ëŠ” ë‚´ì¥ ì˜ˆì‹œ ë°ì´í„°ë¥¼ ì‚¬ìš© ì¤‘ì…ë‹ˆë‹¤.")
else:
    st.subheader("ì‚¬ìš©ì ë°ì´í„° ì‹œê°í™” (ì˜ˆì‹œ)")
    # ì§‘ë‹¨(group) ìˆ˜ì— ë”°ë¼ ìë™ìœ¼ë¡œ ì°¨íŠ¸ ì„ íƒ
    groups = user_df['group'].unique()
    if len(groups) == 1:
        # ë‹¨ì¼ ì‹œê³„ì—´ -> êº¾ì€ì„ /ë©´ì 
        df_u = user_df.copy().sort_values('date')
        if smoothing_user and user_window > 1:
            df_u['smoothed'] = df_u['value'].rolling(window=user_window, min_periods=1, center=True).mean()
            y_col = 'smoothed'
        else:
            y_col = 'value'
        fig_u = px.line(df_u, x='date', y=y_col, markers=True, labels={'date':'ë‚ ì§œ','value':'ê°’'}, title="ì‚¬ìš©ì ì…ë ¥ ì‹œê³„ì—´(ë‹¨ì¼ ê·¸ë£¹)")
        st.plotly_chart(fig_u, use_container_width=True)
    else:
        # ë‹¤ì¤‘ ê·¸ë£¹ -> ê·¸ë£¹ë³„ êº¾ì€ì„ (ë²”ë¡€) ë˜ëŠ” ë©´ì  ëˆ„ì 
        df_u = user_df.copy().sort_values('date')
        if smoothing_user and user_window > 1:
            df_u['smoothed'] = df_u.groupby('group')['value'].transform(lambda s: s.rolling(window=user_window, min_periods=1, center=True).mean())
            y_col = 'smoothed'
        else:
            y_col = 'value'
        fig_u = px.line(df_u, x='date', y=y_col, color='group', markers=True, labels={'date':'ë‚ ì§œ','value':'ê°’','group':'ê·¸ë£¹'}, title="ì‚¬ìš©ì ì…ë ¥ ì‹œê³„ì—´ (ê·¸ë£¹ë³„)")
        st.plotly_chart(fig_u, use_container_width=True)

    # ë¹„ìœ¨í˜• (group í•©ê³„ -> ë„ë„›)
    st.subheader("ê·¸ë£¹ë³„ í•©ê³„ ë¹„ìœ¨")
    group_sum = user_df.groupby('group', as_index=False)['value'].sum()
    fig_pie = px.pie(group_sum, values='value', names='group', hole=0.45, title="ê·¸ë£¹ë³„ ê°’ ë¹„ìœ¨ (ë„ë„›)")
    st.plotly_chart(fig_pie, use_container_width=True)

    # ì§€ë„ ì‹œê°í™”: ë§Œì•½ 'lat' & 'lon' ì—´ì´ ìˆìœ¼ë©´ ì§€ë„ ìë™ êµ¬ì„±
    if {'lat','lon'}.issubset(user_df.columns):
        st.subheader("ìœ„ì¹˜ ê¸°ë°˜ ì‹œê°í™” (ì§€ë„)")
        map_df = user_df.dropna(subset=['lat','lon'])
        st.map(map_df.rename(columns={'lat':'latitude','lon':'longitude'})[['latitude','longitude']])
    else:
        st.info("ì‚¬ìš©ì ë°ì´í„°ì— 'lat' ë° 'lon' ì—´ì´ ì—†ìœ¼ë¯€ë¡œ ì§€ë„ ì‹œê°í™”ëŠ” ìƒëµí•©ë‹ˆë‹¤.")

    # ì‚¬ìš©ì ë°ì´í„° í‘œ + ë‹¤ìš´ë¡œë“œ
    st.subheader("ì „ì²˜ë¦¬ëœ ì‚¬ìš©ì ë°ì´í„° í‘œ / CSV ë‹¤ìš´ë¡œë“œ")
    st.dataframe(user_df)
    st.download_button("ì‚¬ìš©ì ë°ì´í„° CSV ë‹¤ìš´ë¡œë“œ", data=user_df.to_csv(index=False).encode('utf-8'), file_name="user_data_preprocessed.csv", mime="text/csv")

# -------------------------
# ì¶”ê°€ ë„êµ¬ & ë„ì›€ë§ ì„¹ì…˜
# -------------------------
st.markdown("---")
st.header("ë„ì›€ë§ ë° ì¶”ê°€ ì•ˆë‚´ (ê°„ë‹¨ ìš”ì•½)")

st.markdown("""
- ê³µê°œ ë°ì´í„°ëŠ” NASA GISS GISTEMPì˜ ê³µì‹ CSVë¥¼ ì‹œë„í•˜ì—¬ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
  - CSV URL: `https://data.giss.nasa.gov/gistemp/tabledata_v4/GLB.Ts+dSST.csv`
  - (ì°¸ê³ ) ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ì‹œ ì˜ˆì‹œ ë°ì´í„°ë¡œ ìë™ ëŒ€ì²´í•˜ê³  í™”ë©´ì— ì•ˆë‚´í•©ë‹ˆë‹¤.
- ì‚¬ìš©ì ë°ì´í„°: ì´ í”„ë¡¬í”„íŠ¸ì˜ Input ì„¹ì…˜ì—ì„œ ì œê³µëœ íŒŒì¼/í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤. í˜„ì¬ Inputì´ ë¹„ì–´ìˆì–´ ë‚´ì¥ ì˜ˆì‹œ ë°ì´í„°ë¡œ ë™ì‘ ì‹œì—°í•©ë‹ˆë‹¤.
- kaggle API ì‚¬ìš© ì•ˆë‚´ (ì°¸ê³ )
  1. Kaggle ê³„ì • ìƒì„± í›„ API í† í°(kaggle.json) ë‹¤ìš´ë¡œë“œ
  2. Codespaces / ë¡œì»¬ í™˜ê²½ì— `~/.kaggle/kaggle.json`ìœ¼ë¡œ ìœ„ì¹˜ì‹œí‚µë‹ˆë‹¤.
  3. `pip install kaggle` í›„ `kaggle datasets download -d <dataset>` ì‚¬ìš©.
  4. ë³´ì•ˆìƒ í† í°ì€ ê³µê°œ ì €ì¥ì†Œì— ì˜¬ë¦¬ì§€ ë§ˆì„¸ìš”.
""")

st.caption("ì•± ë²„ì „: Streamlit + GitHub Codespaces ë°ëª¨ â€” ëª¨ë“  ë¼ë²¨/ë²„íŠ¼ì€ í•œêµ­ì–´ë¡œ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
